{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNU1kuzO46IqNfAEBEBC7tz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFB269V7EJTN","executionInfo":{"status":"ok","timestamp":1683491493473,"user_tz":300,"elapsed":2213,"user":{"displayName":"Eder Arley León Gómez","userId":"00393246838614185746"}},"outputId":"1d6d3dc1-3e71-4769-8b50-879ddec66930"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Machine-Learning'...\n","remote: Enumerating objects: 105, done.\u001b[K\n","remote: Counting objects: 100% (105/105), done.\u001b[K\n","remote: Compressing objects: 100% (79/79), done.\u001b[K\n","remote: Total 105 (delta 42), reused 76 (delta 21), pack-reused 0\u001b[K\n","Receiving objects: 100% (105/105), 8.31 MiB | 16.23 MiB/s, done.\n","Resolving deltas: 100% (42/42), done.\n"]}],"source":["!git clone https://github.com/ealeongomez/Machine-Learning.git"]},{"cell_type":"code","source":["%cd /content/Machine-Learning/Attention-mechanisms/Transformer\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxA8YPv9Ehw7","executionInfo":{"status":"ok","timestamp":1683491493473,"user_tz":300,"elapsed":13,"user":{"displayName":"Eder Arley León Gómez","userId":"00393246838614185746"}},"outputId":"359d9c40-c004-4433-fdb4-f3552ff1093f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Machine-Learning/Attention-mechanisms/Transformer\n","EncoderPytorch.py\n"]}]},{"cell_type":"markdown","source":["#**Libraries**"],"metadata":{"id":"8PVvjSoO5qoW"}},{"cell_type":"code","source":["from EncoderPytorch import *"],"metadata":{"id":"k-oFUKnGK74B","executionInfo":{"status":"ok","timestamp":1683491500158,"user_tz":300,"elapsed":6690,"user":{"displayName":"Eder Arley León Gómez","userId":"00393246838614185746"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#**Parameters model**"],"metadata":{"id":"WRVyupq55t7S"}},{"cell_type":"code","source":["d_model = 512                 \n","num_heads = 8               # Multi-head attention\n","drop_prob = 0.1\n","batch_size = 30\n","max_sequence_length = 1000\n","ffn_hidden = 2048           # Feed Forward\n","num_layers = 5"],"metadata":{"id":"s763ShNDM0xa","executionInfo":{"status":"ok","timestamp":1683491832263,"user_tz":300,"elapsed":4,"user":{"displayName":"Eder Arley León Gómez","userId":"00393246838614185746"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"],"metadata":{"id":"dr7f3rOpNFVH","executionInfo":{"status":"ok","timestamp":1683491834258,"user_tz":300,"elapsed":217,"user":{"displayName":"Eder Arley León Gómez","userId":"00393246838614185746"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["x = torch.randn( (batch_size, max_sequence_length, d_model) ) # includes positional encoding\n","out = encoder(x)     "],"metadata":{"id":"dtRr4bD2NHzI","outputId":"fe444e2c-54cb-4a06-aec1-db488c14e272","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------- ATTENTION 1 ------\n","x.size(): torch.Size([30, 1000, 512])\n","qkv.size(): torch.Size([30, 1000, 1536])\n","qkv.size(): torch.Size([30, 1000, 8, 192])\n","qkv.size(): torch.Size([30, 8, 1000, 192])\n","q size: torch.Size([30, 8, 1000, 64]), k size: torch.Size([30, 8, 1000, 64]), v size: torch.Size([30, 8, 1000, 64]), \n","scaled.size() : torch.Size([30, 8, 1000, 1000])\n","values.size(): torch.Size([30, 8, 1000, 64]), attention.size:torch.Size([30, 8, 1000, 1000]) \n","values.size(): torch.Size([30, 1000, 512])\n","out.size(): torch.Size([30, 1000, 512])\n","------- DROPOUT 1 ------\n","------- ADD AND LAYER NORMALIZATION 1 ------\n","Mean (torch.Size([30, 1000, 1]))\n","Standard Deviation  (torch.Size([30, 1000, 1]))\n","y: torch.Size([30, 1000, 512])\n","self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n","out: torch.Size([30, 1000, 512])\n","------- ATTENTION 2 ------\n","x after first linear layer: torch.Size([30, 1000, 2048])\n","x after activation: torch.Size([30, 1000, 2048])\n","x after dropout: torch.Size([30, 1000, 2048])\n","x after 2nd linear layer: torch.Size([30, 1000, 512])\n","------- DROPOUT 2 ------\n","------- ADD AND LAYER NORMALIZATION 2 ------\n","Mean (torch.Size([30, 1000, 1]))\n","Standard Deviation  (torch.Size([30, 1000, 1]))\n","y: torch.Size([30, 1000, 512])\n","self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n","out: torch.Size([30, 1000, 512])\n","------- ATTENTION 1 ------\n","x.size(): torch.Size([30, 1000, 512])\n","qkv.size(): torch.Size([30, 1000, 1536])\n","qkv.size(): torch.Size([30, 1000, 8, 192])\n","qkv.size(): torch.Size([30, 8, 1000, 192])\n","q size: torch.Size([30, 8, 1000, 64]), k size: torch.Size([30, 8, 1000, 64]), v size: torch.Size([30, 8, 1000, 64]), \n"]}]}]}